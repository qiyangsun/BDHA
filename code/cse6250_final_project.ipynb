{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M-HwqL08C81t"
      ],
      "mount_file_id": "1jtUvbmQO78Er6eEPXo_AgK_3lkXEopPZ",
      "authorship_tag": "ABX9TyPpBq8fNldsL7V+FY4/RYgy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qiyangsun/BDHA/blob/main/code/cse6250_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v88cTUTSQXDl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "from torch.utils.data import DataLoader, TensorDataset,Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yP5ttE4pRewS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e9711f-92f0-4e90-a4da-da9512ca90d7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        \"\"\"\n",
        "        sequences: List of padded tensors, each tensor is a sequence.\n",
        "        labels: Tensor containing labels corresponding to each sequence.\n",
        "        \"\"\"\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sequences[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "prv5P7swVJG4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "INPUT_SIZE = 69  # Features in the dataset\n",
        "NUM_CLASSES = 2  # Binary classification"
      ],
      "metadata": {
        "id": "VmUJ4GPZ1asZ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/drive/MyDrive/Colab Notebooks/tensor_sequence.csv\"  # Update path accordingly\n",
        "data = pd.read_csv(csv_file_path)\n",
        "data.fillna(data.median(), inplace=True)\n"
      ],
      "metadata": {
        "id": "c5_FWiXJTvmk"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ASVMQf5PURwz",
        "outputId": "28cd8f8b-0157-4068-bbce-6358925bbace"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        batch_idx  time_idx  temperature_r  heartrate_r  resprate_r  o2sat_r  \\\n",
              "0               0         0           97.5        102.0        18.0      0.0   \n",
              "1               0         1           98.0         91.0        16.0     98.0   \n",
              "2               0         2           98.1        100.0        18.0     98.0   \n",
              "3               0         3            0.0          0.0         0.0      0.0   \n",
              "4               0         4            0.0          0.0         0.0      0.0   \n",
              "...           ...       ...            ...          ...         ...      ...   \n",
              "490386       4498       104            0.0          0.0         0.0      0.0   \n",
              "490387       4498       105            0.0          0.0         0.0      0.0   \n",
              "490388       4498       106            0.0          0.0         0.0      0.0   \n",
              "490389       4498       107            0.0          0.0         0.0      0.0   \n",
              "490390       4498       108            0.0          0.0         0.0      0.0   \n",
              "\n",
              "        sbp_r  dbp_r  sepsis  stay_length_hrs  ...     dbp_1     dbp_2  \\\n",
              "0       131.0   71.0     0.0             9.95  ...  5.837371  6.002668   \n",
              "1       138.0   63.0     0.0             9.95  ...  3.916302  4.062122   \n",
              "2       132.0   78.0     0.0             9.95  ...  7.116859  7.010448   \n",
              "3         0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "4         0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "...       ...    ...     ...              ...  ...       ...       ...   \n",
              "490386    0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "490387    0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "490388    0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "490389    0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "490390    0.0    0.0     0.0             0.00  ...  0.000000  0.000000   \n",
              "\n",
              "           dbp_3     dbp_4     dbp_5     dbp_6     dbp_7     dbp_8  \\\n",
              "0       5.910049  6.038254  5.900535  5.819177  5.943805  5.903796   \n",
              "1       3.905994  3.867325  4.052969  3.990040  3.869399  3.909681   \n",
              "2       7.137728  7.043869  6.927984  7.061059  7.034362  7.084827   \n",
              "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "4       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "...          ...       ...       ...       ...       ...       ...   \n",
              "490386  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "490387  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "490388  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "490389  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "490390  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "        gender_encoded  race_r_encoded  \n",
              "0                  0.0             3.0  \n",
              "1                  0.0             3.0  \n",
              "2                  0.0             3.0  \n",
              "3                  0.0             0.0  \n",
              "4                  0.0             0.0  \n",
              "...                ...             ...  \n",
              "490386             0.0             0.0  \n",
              "490387             0.0             0.0  \n",
              "490388             0.0             0.0  \n",
              "490389             0.0             0.0  \n",
              "490390             0.0             0.0  \n",
              "\n",
              "[490391 rows x 70 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca5289e7-eb5a-4bfb-aa8e-cb9723d3738f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_idx</th>\n",
              "      <th>time_idx</th>\n",
              "      <th>temperature_r</th>\n",
              "      <th>heartrate_r</th>\n",
              "      <th>resprate_r</th>\n",
              "      <th>o2sat_r</th>\n",
              "      <th>sbp_r</th>\n",
              "      <th>dbp_r</th>\n",
              "      <th>sepsis</th>\n",
              "      <th>stay_length_hrs</th>\n",
              "      <th>...</th>\n",
              "      <th>dbp_1</th>\n",
              "      <th>dbp_2</th>\n",
              "      <th>dbp_3</th>\n",
              "      <th>dbp_4</th>\n",
              "      <th>dbp_5</th>\n",
              "      <th>dbp_6</th>\n",
              "      <th>dbp_7</th>\n",
              "      <th>dbp_8</th>\n",
              "      <th>gender_encoded</th>\n",
              "      <th>race_r_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>97.5</td>\n",
              "      <td>102.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.95</td>\n",
              "      <td>...</td>\n",
              "      <td>5.837371</td>\n",
              "      <td>6.002668</td>\n",
              "      <td>5.910049</td>\n",
              "      <td>6.038254</td>\n",
              "      <td>5.900535</td>\n",
              "      <td>5.819177</td>\n",
              "      <td>5.943805</td>\n",
              "      <td>5.903796</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.95</td>\n",
              "      <td>...</td>\n",
              "      <td>3.916302</td>\n",
              "      <td>4.062122</td>\n",
              "      <td>3.905994</td>\n",
              "      <td>3.867325</td>\n",
              "      <td>4.052969</td>\n",
              "      <td>3.990040</td>\n",
              "      <td>3.869399</td>\n",
              "      <td>3.909681</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>98.1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.95</td>\n",
              "      <td>...</td>\n",
              "      <td>7.116859</td>\n",
              "      <td>7.010448</td>\n",
              "      <td>7.137728</td>\n",
              "      <td>7.043869</td>\n",
              "      <td>6.927984</td>\n",
              "      <td>7.061059</td>\n",
              "      <td>7.034362</td>\n",
              "      <td>7.084827</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490386</th>\n",
              "      <td>4498</td>\n",
              "      <td>104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490387</th>\n",
              "      <td>4498</td>\n",
              "      <td>105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490388</th>\n",
              "      <td>4498</td>\n",
              "      <td>106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490389</th>\n",
              "      <td>4498</td>\n",
              "      <td>107</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490390</th>\n",
              "      <td>4498</td>\n",
              "      <td>108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>490391 rows × 70 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca5289e7-eb5a-4bfb-aa8e-cb9723d3738f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca5289e7-eb5a-4bfb-aa8e-cb9723d3738f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca5289e7-eb5a-4bfb-aa8e-cb9723d3738f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-edbeb040-8058-457c-b60d-3265d1d85b75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-edbeb040-8058-457c-b60d-3265d1d85b75')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-edbeb040-8058-457c-b60d-3265d1d85b75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_044a67a6-7ed7-4772-b114-713f6f3a6983\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_044a67a6-7ed7-4772-b114-713f6f3a6983 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.loc[:, data.columns != \"sepsis\"]  # All columns except the last\n",
        "y = data[\"sepsis\"].values   # Last column\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "y3GiMttc0Zmq"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlD7_7rWXElk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors and create DataLoader\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "Q3JNBo0_1Cmj"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add a dummy sequence dimension for RNN\n",
        "        x = x.unsqueeze(1)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])  # Use the last time step\n",
        "        return out\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            outputs = model(X_batch)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
        "            y_true.extend(y_batch.numpy())\n",
        "            y_pred.extend(preds.numpy())\n",
        "            y_probs.extend(probs.numpy())\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_probs)\n",
        "    return cm, auc"
      ],
      "metadata": {
        "id": "dyKcqUDO1sKB"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Function to perform hyperparameter tuning\n",
        "def hyperparameter_tuning(train_loader, model,test_loader, input_size, num_classes, param_grid, epochs):\n",
        "    best_auc = 0\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "\n",
        "    # Generate all combinations of hyperparameters\n",
        "    for params in itertools.product(*param_grid.values()):\n",
        "        param_dict = dict(zip(param_grid.keys(), params))\n",
        "        print(f\"Testing parameters: {param_dict}\")\n",
        "\n",
        "        # Initialize model, criterion, and optimizer with current parameters\n",
        "        if model == 'RNN':\n",
        "          model = RNNModel(input_size,\n",
        "                          hidden_size=param_dict['hidden_size'],\n",
        "                          num_layers=param_dict['num_layers'],\n",
        "                          num_classes=num_classes)\n",
        "        elif model == 'BiLSTM':\n",
        "          model = BiLSTM(input_size,\n",
        "                          hidden_size=param_dict['hidden_size'],\n",
        "                          num_layers=param_dict['num_layers'],\n",
        "                          num_classes=num_classes)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=param_dict['learning_rate'])\n",
        "\n",
        "        # Train the model\n",
        "        train_model(model, train_loader, criterion, optimizer, epochs)\n",
        "\n",
        "        # Evaluate the model\n",
        "        cm, auc = evaluate_model(model, test_loader)\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "        print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "        # Update best model if necessary\n",
        "        if auc > best_auc:\n",
        "            best_auc = auc\n",
        "            best_params = param_dict\n",
        "            best_model = model\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best AUC: {best_auc:.4f}\")\n",
        "    return best_model, best_params, best_auc\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'hidden_size': [64, 128],\n",
        "    'num_layers': [1, 2],\n",
        "    'learning_rate': [0.0003,0.0005,0.0008],\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "best_model, best_params, best_auc = hyperparameter_tuning(\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    input_size=INPUT_SIZE,\n",
        "    model='RNN',\n",
        "    num_classes=NUM_CLASSES,\n",
        "    param_grid=param_grid,\n",
        "    epochs=10,\n",
        ")\n",
        "\n",
        "print(\"Hyperparameter tuning complete.\")\n",
        "print(f\"Best Model: {best_model}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best AUC: {best_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "rcLxc6Ik2pUG",
        "outputId": "40e32b6d-5f88-444a-930f-f0e66d7ddda6"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0003}\n",
            "Epoch [1/10], Loss: 0.0311\n",
            "Epoch [2/10], Loss: 0.0184\n",
            "Epoch [3/10], Loss: 0.0182\n",
            "Epoch [4/10], Loss: 0.0179\n",
            "Epoch [5/10], Loss: 0.0178\n",
            "Epoch [6/10], Loss: 0.0177\n",
            "Epoch [7/10], Loss: 0.0176\n",
            "Epoch [8/10], Loss: 0.0175\n",
            "Epoch [9/10], Loss: 0.0174\n",
            "Epoch [10/10], Loss: 0.0174\n",
            "Confusion Matrix:\n",
            "[[96928   149]\n",
            " [  649   353]]\n",
            "AUC: 0.9945\n",
            "Testing parameters: {'hidden_size': 64, 'num_layers': 1, 'learning_rate': 0.0005}\n",
            "Epoch [1/10], Loss: 0.0178\n",
            "Epoch [2/10], Loss: 0.0177\n",
            "Epoch [3/10], Loss: 0.0176\n",
            "Epoch [4/10], Loss: 0.0176\n",
            "Epoch [5/10], Loss: 0.0175\n",
            "Epoch [6/10], Loss: 0.0176\n",
            "Epoch [7/10], Loss: 0.0175\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-9b6dd31b25e5>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Perform hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m best_model, best_params, best_auc = hyperparameter_tuning(\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-9b6dd31b25e5>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(train_loader, model, test_loader, input_size, num_classes, param_grid, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-123-a1c9d7c8c2c6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         self.record = torch.ops.profiler._record_function_enter_new(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bi-LSTM"
      ],
      "metadata": {
        "id": "Vhkx4m8prC5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Dataset Preparation\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "def preprocess_data(filepath, target_col='sepsis', chunk_size=5000):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(filepath)\n",
        "    data.fillna(data.median(), inplace=True)  # Fill missing values\n",
        "    features = [col for col in data.columns if col not in [target_col, 'unique_id']]\n",
        "\n",
        "    # Sample a chunk if needed\n",
        "    data = data.sample(n=chunk_size, random_state=42)\n",
        "    X = data[features].values.astype(np.float32)\n",
        "    y = data[target_col].values.astype(np.float32)\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = MinMaxScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Reshape X for LSTM (batch_size, seq_len=1, input_size)\n",
        "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Step 2: Define Bi-LSTM Model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # 2 for bidirectional\n",
        "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_len, hidden_size*2)\n",
        "\n",
        "        # Decode the last hidden state\n",
        "        out = self.fc(out[:, -1, :])  # Only take the output of the last time step\n",
        "        return out\n",
        "\n",
        "# Step 3: Train and Evaluate the Model\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            labels = labels.unsqueeze(1)  # Match output dimensions\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Collect true labels and predicted probabilities\n",
        "            all_labels.append(labels.cpu())\n",
        "            all_outputs.append(torch.sigmoid(outputs).cpu())  # Apply sigmoid to get probabilities\n",
        "\n",
        "    # Concatenate all predictions and labels\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    all_outputs = torch.cat(all_outputs).numpy()\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc_score = roc_auc_score(all_labels, all_outputs)\n",
        "    print(f\"AUC: {auc_score:.4f}\")"
      ],
      "metadata": {
        "id": "q5GtvHxcrqaF"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filepath to dataset\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/tensor_sequence.csv\"  # Replace with your dataset path\n",
        "\n",
        "# Preprocess data\n",
        "X_train, X_test, y_train, y_test = preprocess_data(filepath)\n",
        "\n",
        "# Create PyTorch Datasets and DataLoaders\n",
        "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = X_train.shape[2]\n",
        "hidden_size = 64\n",
        "output_size = 1  # Binary classification\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BiLSTM(input_size, hidden_size, output_size).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train and evaluate the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=30)\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYhMrQenrEC2",
        "outputId": "894b196e-7056-4ac8-e657-3e652a3e3380"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 0.6873\n",
            "Epoch [2/30], Loss: 0.6686\n",
            "Epoch [3/30], Loss: 0.6045\n",
            "Epoch [4/30], Loss: 0.5619\n",
            "Epoch [5/30], Loss: 0.5380\n",
            "Epoch [6/30], Loss: 0.4748\n",
            "Epoch [7/30], Loss: 0.4015\n",
            "Epoch [8/30], Loss: 0.3958\n",
            "Epoch [9/30], Loss: 0.3487\n",
            "Epoch [10/30], Loss: 0.2818\n",
            "Epoch [11/30], Loss: 0.2603\n",
            "Epoch [12/30], Loss: 0.2161\n",
            "Epoch [13/30], Loss: 0.1542\n",
            "Epoch [14/30], Loss: 0.1405\n",
            "Epoch [15/30], Loss: 0.1292\n",
            "Epoch [16/30], Loss: 0.0960\n",
            "Epoch [17/30], Loss: 0.0841\n",
            "Epoch [18/30], Loss: 0.0653\n",
            "Epoch [19/30], Loss: 0.1812\n",
            "Epoch [20/30], Loss: 0.0842\n",
            "Epoch [21/30], Loss: 0.0615\n",
            "Epoch [22/30], Loss: 0.0345\n",
            "Epoch [23/30], Loss: 0.0668\n",
            "Epoch [24/30], Loss: 0.0897\n",
            "Epoch [25/30], Loss: 0.0359\n",
            "Epoch [26/30], Loss: 0.0224\n",
            "Epoch [27/30], Loss: 0.0974\n",
            "Epoch [28/30], Loss: 0.0190\n",
            "Epoch [29/30], Loss: 0.0389\n",
            "Epoch [30/30], Loss: 0.0191\n",
            "AUC: 0.9951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-bYONDorJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5cFWfLlC8Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross validation\n"
      ],
      "metadata": {
        "id": "M-HwqL08C81t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Step 1: Define the RNN Model\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])  # Use the last output of the sequence\n",
        "        return out\n",
        "\n",
        "# Step 2: Cross-Validation Function\n",
        "def cross_validate_rnn(X, y, model_class, input_size, hidden_size, output_size, num_layers=1, k=5, num_epochs=10, batch_size=32):\n",
        "    kf = KFold(n_splits=k)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "\n",
        "        # Split data into training and validation sets\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # Create DataLoaders\n",
        "        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Initialize model, loss function, and optimizer\n",
        "        model = model_class(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        # Train the model\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Average validation loss and accuracy\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = correct / total\n",
        "        fold_results.append({'loss': val_loss, 'accuracy': val_accuracy})\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Aggregate results across folds\n",
        "    avg_loss = np.mean([result['loss'] for result in fold_results])\n",
        "    avg_accuracy = np.mean([result['accuracy'] for result in fold_results])\n",
        "    print(f\"Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}\")\n",
        "\n",
        "    return fold_results\n",
        "\n",
        "# Step 3: Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example dataset (replace with real data)\n",
        "    X = np.random.rand(1000, 10, 5)  # 1000 samples, 10 sequence length, 5 features\n",
        "    y = np.random.randint(0, 2, size=(1000,))  # Binary labels\n",
        "\n",
        "    input_size = 5\n",
        "    hidden_size = 64\n",
        "    output_size = 1\n",
        "    num_layers = 1\n",
        "    num_epochs = 10\n",
        "    batch_size = 32\n",
        "\n",
        "    cross_validate_rnn(X, y, RNNModel, input_size, hidden_size, output_size, num_layers, k=5, num_epochs=num_epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "FW1L_j1tC_VQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}